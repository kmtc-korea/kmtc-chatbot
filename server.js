// backend/server.js â€“ KMTC AI 2025-06-12 (vFuncCall)
// Â· í•¨ìˆ˜ í˜¸ì¶œ(Function Calling)ìœ¼ë¡œ AIê°€ ìŠ¤ìŠ¤ë¡œ ì˜ë„ íŒŒì•…â†’ê±°ë¦¬ ê³„ì‚°â†’ë¹„ìš© ì‚°ì¶œê¹Œì§€ ì²˜ë¦¬
// Â· Google Distance Matrix APIë§Œ ì‚¬ìš©
// Â· data/structured_ë‹¨ê°€í‘œ.json ì— ìžˆëŠ” â€œë‹¨ê°€â€ì™€ â€œê³„ì‚°ë°©ì‹â€ë§Œ ì°¸ì¡°
// Â· ì‘ë‹µì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ, ê³µê°Â·ì• ë„ í‘œí˜„ í¬í•¨
// Â· ì„¸ì…˜ ë™ì•ˆ ëŒ€í™” ì´ë ¥ ìœ ì§€

import express from "express";
import cors from "cors";
import { config } from "dotenv";
import fetch from "node-fetch";
import { OpenAI } from "openai";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";

config();
const __dirname       = path.dirname(fileURLToPath(import.meta.url));
const GMAPS_KEY       = process.env.GMAPS_KEY;
const OPENAI_API_KEY  = process.env.OPENAI_API_KEY;

// â”€â”€â”€ ë‹¨ê°€í‘œ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const prices = JSON.parse(
  fs.readFileSync(path.join(__dirname, "data/structured_ë‹¨ê°€í‘œ.json"), "utf8")
);

// â”€â”€â”€ Google Distance Matrix API í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function getDistance({ origin, destination }) {
  const url = `https://maps.googleapis.com/maps/api/distancematrix/json` +
    `?origins=${encodeURIComponent(origin)}` +
    `&destinations=${encodeURIComponent(destination)}` +
    `&key=${GMAPS_KEY}&language=ko`;
  const js = await fetch(url).then(r => r.json());
  const elem = js.rows?.[0]?.elements?.[0];
  if (!elem || elem.status !== "OK" || !elem.distance) {
    throw new Error(`ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨: status=${elem?.status}`);
  }
  return {
    km:  Math.round(elem.distance.value / 1000),
    hr: +(elem.duration.value / 3600).toFixed(1)
  };
}

// â”€â”€â”€ ë¹„ìš© ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function computeCost({ context, transport, km, days, patient }) {
  // 1) AI í”Œëžœ ìƒì„± (JSON ONLY)
  const openai = new OpenAI({ apiKey: OPENAI_API_KEY });
  const planRes = await openai.chat.completions.create({
    model: "gpt-4o",
    temperature: 0.2,
    messages:[
      {
        role: "system",
        content: `JSON ONLY:
{"type":"air|funeral|event","cremated":bool,"risk":"low|medium|high","transport":"civil|airAmbulance|charter|ship","seat":"business|stretcher","staff":["doctor","nurse"],"equipment":{"ventilator":bool,"ecmo":bool},"medLvl":"low|medium|high","notes":["..."]}`
      },
      { role: "user", content:
        `ì§„ë‹¨:${patient.diagnosis||"unknown"} / ì˜ì‹:${patient.consciousness||"unknown"}` +
        ` / ê±°ë™:${patient.mobility||"unknown"} / ê±°ë¦¬:${km}`
      }
    ]
  });
  let plan0;
  try {
    plan0 = JSON.parse(planRes.choices[0].message.content.trim());
  } catch {
    // ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”Œëžœ
    plan0 = {
      type: "air",
      cremated: false,
      risk: "medium",
      transport,
      seat: "business",
      staff: ["doctor","nurse"],
      equipment: { ventilator:true, ecmo:false },
      medLvl: "medium",
      notes: []
    };
  }

  // 2) ì‹¤ì œ ë¹„ìš© ê³„ì‚°
  const ctxKey = plan0.type==="funeral" ? "ê³ ì¸ì´ì†¡"
               : plan0.type==="event"   ? "í–‰ì‚¬ì§€ì›"
               :                           "í•­ê³µì´ì†¡";
  let total = 0;
  (prices[ctxKey]||[]).forEach(item => {
    const u = item.ë‹¨ê°€;
    switch(item.ê³„ì‚°ë°©ì‹) {
      case "ë‹¨ê°€xê±°ë¦¬":
        total += u * km; break;
      case "ë‹¨ê°€xê±°ë¦¬xì¸ì›":
        total += u * km * (plan0.staff.length||1); break;
      case "ë‹¨ê°€xì¼ìˆ˜":
        total += u * days; break;
      case "ë‹¨ê°€xì¼ìˆ˜xì¸ì›":
        total += u * days * (plan0.staff.length||1); break;
      case "ë‹¨ê°€":
        total += u; break;
    }
  });

  return { plan: plan0, context: ctxKey, km, hr:0, total };
}

// â”€â”€â”€ Function Calling ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const functions = [
  {
    name: "getDistance",
    description: "ì¶œë°œì§€ì™€ ë„ì°©ì§€ ê°„ ê±°ë¦¬(km)ì™€ ì‹œê°„(hr)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.",
    parameters: {
      type: "object",
      properties: {
        origin:      { type: "string", description: "ì¶œë°œì§€ ì£¼ì†Œ ë˜ëŠ” ìž¥ì†Œ" },
        destination: { type: "string", description: "ë„ì°©ì§€ ì£¼ì†Œ ë˜ëŠ” ìž¥ì†Œ" }
      },
      required: ["origin","destination"]
    }
  },
  {
    name: "computeCost",
    description: "context, transport, ê±°ë¦¬, ì¼ìˆ˜, patient ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ìš©ì„ ê³„ì‚°í•©ë‹ˆë‹¤.",
    parameters:{
      type:"object",
      properties:{
        context:   { type:"string", enum:["í•­ê³µì´ì†¡","ê³ ì¸ì´ì†¡","í–‰ì‚¬ì§€ì›"] },
        transport: { type:"string" },
        km:        { type:"number" },
        days:      { type:"number" },
        patient:   { type:"object" }
      },
      required:["context","transport","km","days"]
    }
  }
];

// â”€â”€â”€ Express ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const app = express();
app.use(cors());
app.use(express.json());

const sessions = {};

app.post("/chat", async (req, res) => {
  const { sessionId="def", message="", days=1, patient={} } = req.body;
  const ses = sessions[sessionId] ||= {
    history: [{
      role: "system",
      content: `
ë‹¹ì‹ ì€ KMTC AI ìƒë‹´ì›ìž…ë‹ˆë‹¤.
- ì„œë¹„ìŠ¤: í•­ê³µì´ì†¡, ê³ ì¸ì´ì†¡, í–‰ì‚¬ ì˜ë£Œì§€ì›
- ë¹„ìš© ê³„ì‚°: data/structured_ë‹¨ê°€í‘œ.jsonë§Œ ì°¸ì¡°
- ê±°ë¦¬ ê³„ì‚°: Google Distance Matrix API
- ì‘ë‹µì€ ë§ˆí¬ë‹¤ìš´, ê³µê°Â·ì• ë„ í‘œí˜„ í¬í•¨
- íƒ€ì—…ì²´ ì–¸ê¸‰ ê¸ˆì§€`
    }]
  };

  // 1) AIì—ê²Œ ì˜ë„ ë¶„ì„+í•¨ìˆ˜ í˜¸ì¶œ ìš”ì²­
  ses.history.push({ role:"user", content: message });
  const first = await new OpenAI({ apiKey: OPENAI_API_KEY })
    .chat.completions.create({
      model: "gpt-4o",
      messages: ses.history,
      functions,
      function_call: "auto"
    });

  const msg = first.choices[0].message;
  ses.history.push(msg);

  // 2) getDistance í˜¸ì¶œ í•„ìš” ì‹œ ì‹¤ì œ ì‹¤í–‰
  if (msg.function_call?.name === "getDistance") {
    const args = JSON.parse(msg.function_call.arguments);
    let dist;
    try {
      dist = await getDistance(args);
    } catch (err) {
      const warn = "âš ï¸ ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨. ì£¼ì†Œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.";
      ses.history.push({ role:"assistant", content: warn });
      return res.json({ reply: warn });
    }
    // í˜¸ì¶œ ê²°ê³¼ë¥¼ AIì—ê²Œ ë‹¤ì‹œ ì „ë‹¬
    ses.history.push({
      role: "function",
      name: "getDistance",
      content: JSON.stringify(dist)
    });
    const second = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: ses.history,
      functions,
      function_call: "auto"
    });
    ses.history.push(second.choices[0].message);
    // ì´ì œ computeCost í˜¸ì¶œ
    return completeCost(second.choices[0].message);
  }

  // 3) computeCost í˜¸ì¶œ í•„ìš” ì‹œ
  if (msg.function_call?.name === "computeCost") {
    return completeCost(msg);
  }

  // 4) ì¼ë°˜ ë‹µë³€
  const reply = msg.content;
  return res.json({ reply });
  
  // â€” ë‚´ë¶€ í—¬í¼: computeCostë¥¼ ì‹¤í–‰í•˜ê³  ìµœì¢… ì‘ë‹µ
  async function completeCost(fnMsg) {
    const args = JSON.parse(fnMsg.function_call.arguments);
    const costRes = await computeCost({
      context: args.context,
      transport: args.transport,
      km: args.km,
      days,
      patient
    });
    ses.history.push({
      role: "function",
      name: "computeCost",
      content: JSON.stringify(costRes)
    });
    // ìµœì¢… ë Œë”ë§
    const final = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: ses.history
    });
    const finalReply = final.choices[0].message.content;
    ses.history.push({ role:"assistant", content: finalReply });
    return res.json({ reply: finalReply });
  }
});

app.listen(3000, () => console.log("ðŸš€ KMTC AI running on port 3000"));
